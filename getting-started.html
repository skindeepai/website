<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Getting Started with PLGL - Preference Learning in Generative Latent Spaces</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <div class="logo-container">
                <div class="logo">PLGL</div>
                <span class="logo-subtitle">by SkinDeep.ai Inc</span>
            </div>
            <ul class="nav-menu">
                <li><a href="index.html">Home</a></li>
                <li><a href="how-it-works.html">How It Works</a></li>
                <li><a href="index.html#applications">Applications</a></li>
                <li><a href="index.html#demos">Demos</a></li>
                <li><a href="getting-started.html" class="active">Get Started</a></li>
				<li><a href="about.html">About</a></li>
                <li><a href="https://github.com/skindeepai" class="github-link">GitHub</a></li>
                <li><a href="https://skindeep.ai" class="company-link">SkinDeep.ai</a></li>
            </ul>
        </div>
    </nav>

    <div class="docs-container">
        <aside class="docs-sidebar">
            <h3>Getting Started</h3>
            <ul>
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#installation">Installation</a></li>
                <li><a href="#quickstart">Quick Start</a></li>
                <li><a href="#concepts">Core Concepts</a></li>
                <li><a href="#first-project">Your First Project</a></li>
                <li><a href="#advanced">Advanced Usage</a></li>
                <li><a href="#examples">Example Projects</a></li>
                <li><a href="#troubleshooting">Troubleshooting</a></li>
            </ul>
        </aside>

        <main class="docs-content">
            <h1>Getting Started with PLGL</h1>
            <p class="lead">Build personalized AI applications using preference learning and generative models</p>

            <section id="introduction">
                <h2>Introduction</h2>
                <p>PLGL (Preference Learning in Generative Latent Spaces) enables you to create AI applications that learn and adapt to individual user preferences. This guide will walk you through everything you need to start building with PLGL.</p>
                
                <div class="info-box">
                    <h4>What You'll Learn</h4>
                    <ul>
                        <li>How to set up PLGL in your project</li>
                        <li>Understanding the core concepts</li>
                        <li>Building your first preference-learning application</li>
                        <li>Best practices and optimization techniques</li>
                    </ul>
                </div>
            </section>

            <section id="installation">
                <h2>Understanding PLGL</h2>
                
                <div class="warning-box">
                    <h4>Important Note</h4>
                    <p>PLGL is a methodology and approach, not a specific software package. There is no "pip install plgl" command. Instead, PLGL describes how to use preference learning with any generative model that has a latent space.</p>
                </div>
                
                <h3>What You Need</h3>
                <p>To implement PLGL, you'll need:</p>
                <ul>
                    <li>A generative model with a latent space (e.g., StyleGAN, Stable Diffusion, VAE)</li>
                    <li>A machine learning framework (PyTorch, TensorFlow, JAX, etc.)</li>
                    <li>A way to collect user preferences (UI for ratings)</li>
                </ul>
                
                <h3>Reference Implementation</h3>
                <p>For the original 2018-2019 implementation approach, see:</p>
                <ul>
                    <li><a href="https://github.com/skindeepai">SkinDeep.ai Core Repository</a></li>
                    <li><a href="whitepaper.html">PLGL Whitepaper</a></li>
                </ul>

                <h3>Requirements</h3>
                <ul>
                    <li>Python 3.8+</li>
                    <li>A deep learning framework (PyTorch, TensorFlow, or JAX)</li>
                    <li>A pre-trained generative model with accessible latent space</li>
                </ul>
            </section>

            <section id="quickstart">
                <h2>Quick Start</h2>
                <p>Here's the conceptual flow of implementing PLGL:</p>

                <div class="concept-flow">
                    <h3>The PLGL Process</h3>
                    <ol>
                        <li>
                            <h4>Generate Sample Content</h4>
                            <p>Use your generative model to create diverse samples by sampling different points in the latent space.</p>
                        </li>
                        <li>
                            <h4>Collect User Feedback</h4>
                            <p>Present samples to users and collect simple feedback (like/dislike, ratings, or implicit signals).</p>
                        </li>
                        <li>
                            <h4>Train Preference Classifier</h4>
                            <p>Build a model that learns to predict user preferences based on latent space coordinates.</p>
                        </li>
                        <li>
                            <h4>Find Optimal Region</h4>
                            <p>Use reverse classification to find latent vectors that maximize preference scores.</p>
                        </li>
                        <li>
                            <h4>Generate Personalized Content</h4>
                            <p>Create new content using the optimal latent vectors.</p>
                        </li>
                    </ol>
                </div>
                
                <div class="info-box">
                    <h4>Example Workflow</h4>
                    <p>If you're using StyleGAN for face generation:</p>
                    <ol>
                        <li>Generate 20 random faces</li>
                        <li>User swipes left/right (dislike/like)</li>
                        <li>Train a neural network: latent vector ‚Üí preference score</li>
                        <li>Use gradient ascent to find high-scoring latent vectors</li>
                        <li>Generate faces the user will love</li>
                    </ol>
                </div>
            </section>

            <section id="concepts">
                <h2>Core Concepts</h2>

                <h3>1. Generative Models & Latent Spaces</h3>
                <p>PLGL works with any generative model that has a continuous latent space. This includes:</p>
                <ul>
                    <li><strong>GANs</strong> (StyleGAN, ProGAN, etc.)</li>
                    <li><strong>VAEs</strong> (Variational Autoencoders)</li>
                    <li><strong>Diffusion Models</strong> with latent representations</li>
                    <li><strong>Any model</strong> where inputs map to outputs through a continuous space</li>
                </ul>

                <h3>2. Preference Learning</h3>
                <p>PLGL learns preferences through various rating mechanisms:</p>
                <ul>
                    <li><strong>Binary preferences:</strong> Like/dislike, thumbs up/down</li>
                    <li><strong>Scaled preferences:</strong> 1-5 star ratings</li>
                    <li><strong>Comparative preferences:</strong> Choose A or B</li>
                    <li><strong>Implicit signals:</strong> Watch time, skip behavior, engagement</li>
                </ul>
                
                <div class="concept-note">
                    <p>The key insight: Users don't need to describe what they want. They just need to react to what they see, and PLGL learns the patterns.</p>
                </div>

                <h3>3. Latent Space Navigation</h3>
                <p>PLGL optimizes through the latent space to find content matching learned preferences:</p>
                <ul>
                    <li><strong>Gradient-based optimization:</strong> Use gradients to climb toward high-preference regions</li>
                    <li><strong>Evolutionary optimization:</strong> For non-differentiable models</li>
                    <li><strong>Bayesian optimization:</strong> Sample-efficient exploration</li>
                    <li><strong>Distribution generation:</strong> Create variety while maintaining quality</li>
                </ul>
                
                <div class="concept-note">
                    <p><strong>Reverse Classification:</strong> Instead of asking "what score does this content get?", PLGL asks "what latent vector gives a perfect score?"</p>
                </div>
            </section>

            <section id="first-project">
                <h2>Your First PLGL Project</h2>
                <p>Let's build a complete preference-learning application step by step.</p>

                <h3>Project: Personalized Art Generator</h3>

                <h4>Step 1: Setup Your Generative Model</h4>
                <div class="concept-box">
                    <p>First, you'll need to load your chosen generative model. Here's how the original PLGL implementation loads StyleGAN:</p>
                </div>
                <pre><code class="language-python"># Load pre-trained StyleGAN model
import pickle
import dnnlib
import dnnlib.tflib as tflib

tflib.init_tf()

# Load the model (example using StyleGAN for faces)
url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ'
with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:
    _G, _D, Gs = pickle.load(f)
    # Gs = Long-term average of the generator (best quality)</code></pre>
                <div class="concept-box">
                    <p>The key requirement is that your model can generate content from latent vectors (512-dimensional in StyleGAN's case).</p>
                </div>

                <h4>Step 2: Build a Rating Interface</h4>
                <div class="concept-box">
                    <p>Create a simple interface for users to rate generated content. This typically involves:</p>
                    <ul>
                        <li><strong>Display function:</strong> Show the generated content to the user</li>
                        <li><strong>Rating collection:</strong> Capture user feedback (1-5 stars, thumbs up/down, etc.)</li>
                        <li><strong>Data storage:</strong> Save latent vectors with their ratings</li>
                    </ul>
                    <p>The interface can be as simple as a command-line prompt or as sophisticated as a mobile app with swipe gestures.</p>
                </div>

                <h4>Step 3: Collect User Preferences</h4>
                <div class="concept-box">
                    <p>Generate diverse samples and collect user ratings. Here's how the real implementation loads preference data:</p>
                </div>
                <pre><code class="language-python"># Load user preference data from database
import sqlite3
import numpy as np

# Connect to preference database
conn = sqlite3.connect("preferences.db")
c = conn.cursor()
c.execute("SELECT * FROM user_ratings")
rows = c.fetchall()

# Build dataset of latent vectors and ratings
latent_vectors = []
ratings = []
for row in rows:
    # Load the latent vector that generated this image
    latents = np.load(f"results/{row[1]}.npy")
    latent_vectors.append(latents)
    ratings.append(int(row[2]))  # Binary rating: 0 or 1

# Convert to numpy arrays
X = np.vstack(latent_vectors)  # Shape: (n_samples, 512)
y = np.array(ratings)           # Shape: (n_samples,)</code></pre>
                <div class="concept-box">
                    <p><strong>Key insight:</strong> Each generated image is stored with its latent vector, allowing us to map preferences back to the latent space.</p>
                </div>

                <h4>Step 4: Train a Preference Classifier</h4>
                <div class="concept-box">
                    <p>The original PLGL implementation offers two approaches:</p>
                </div>
                
                <h5>Option A: Neural Network Classifier</h5>
                <pre><code class="language-python"># Define simple neural network architecture
NN_ARCHITECTURE = [
    {"input_dim": 512, "output_dim": 1, "activation": "sigmoid"}
]

# Train the preference model
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Custom training function (see full implementation)
params = train(X_train.T, y_train.reshape(-1, 1).T, 
               NN_ARCHITECTURE, epochs=100, learning_rate=0.01)

# Test accuracy
Y_test_hat, _ = full_forward_propagation(X_test.T, params, NN_ARCHITECTURE)
accuracy = get_accuracy_value(Y_test_hat, y_test.reshape(-1, 1).T)
print(f"Test accuracy: {accuracy:.2f}")</code></pre>

                <h5>Option B: SVM Classifier (Faster)</h5>
                <pre><code class="language-python"># Using SVM for fast preference learning
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler

# Normalize the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train SVM classifier
classifier = SVC(C=10, gamma=0.0001, kernel='rbf')
classifier.fit(X_train_scaled, y_train)

# Fast prediction on new samples
score = classifier.score(X_test_scaled, y_test)
print(f"SVM accuracy: {score:.2f}")</code></pre>

                <h4>Step 5: Generate Personalized Content</h4>
                <div class="concept-box">
                    <p>The most innovative part: <strong>Reverse Classification‚Ñ¢</strong></p>
                </div>
                <pre><code class="language-python"># Reverse Classification: Find latent vector for desired score
def reverse_classification(target_score, params, nn_architecture):
    """Given a target preference score, find the latent vector"""
    output = np.zeros((512,), dtype="float32")
    
    # Extract trained weights and bias
    W = params["W1"][0]  # Shape: (512,)
    b = params["b1"][0]
    
    # Inverse sigmoid to get pre-activation value
    z = math.log(target_score / (1 - target_score)) - b[0]
    
    # Distribute across latent dimensions
    for i in range(512):
        y = z / W[i]
        if abs(y) >= 1.0:
            output[i] = np.sign(y) * 0.99999
            z -= W[i] * output[i]
        else:
            output[i] = y
            break
    
    return output

# Generate ideal content (99.99% preference score)
ideal_latent = reverse_classification(0.9999, params, NN_ARCHITECTURE)

# Generate the image
images = Gs.run(ideal_latent.reshape(1, -1), None, 
                truncation_psi=0.7, randomize_noise=True)
                
# Save personalized result
PIL.Image.fromarray(images[0], 'RGB').save('personalized_result.png')</code></pre>
                <div class="concept-box">
                    <p><strong>This is the key innovation:</strong> Instead of searching randomly, we directly compute what latent vector will produce the desired preference score!</p>
                </div>

                <h4>Step 6: Iterative Refinement (Optional)</h4>
                <div class="concept-box">
                    <p>Continuously improve the preference model with batch generation:</p>
                </div>
                <pre><code class="language-python"># GPU-optimized batch generation
def generate_batch(classifier, generator, n_samples=100):
    """Generate a batch with 70% exploitation, 30% exploration"""
    batch_latents = []
    
    # 70% exploitation: refine around high-scoring regions
    for _ in range(70):
        # Start from a known good point and add small noise
        good_latent = reverse_classification(0.95, params, NN_ARCHITECTURE)
        noise = np.random.normal(0, 0.1, size=(512,))
        batch_latents.append(good_latent + noise)
    
    # 30% exploration: discover new preferences
    for _ in range(30):
        random_latent = np.random.randn(512)
        batch_latents.append(random_latent)
    
    # Generate all images in one GPU batch
    batch_latents = np.array(batch_latents)
    images = Gs.run(batch_latents, None, truncation_psi=0.7)
    
    return images, batch_latents</code></pre>
                
                <div class="implementation-note">
                    <h4>Implementation Notes from Original Code:</h4>
                    <ul>
                        <li><strong>Database:</strong> SQLite for storing latent vectors with ratings</li>
                        <li><strong>Latent dimension:</strong> 512 for StyleGAN faces</li>
                        <li><strong>Binary classification:</strong> Simple hot/not ratings (0 or 1)</li>
                        <li><strong>Fast training:</strong> 100-1000 epochs typically sufficient</li>
                        <li><strong>Caching:</strong> Pre-generate and cache common samples</li>
                    </ul>
                </div>
            </section>

            <section id="complete-example">
                <h2>Complete Working Example</h2>
                <p>Here's how all the pieces come together in a real PLGL implementation:</p>
                
                <pre><code class="language-python"># Complete PLGL Pipeline Example
import numpy as np
import sqlite3
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# 1. LOAD YOUR GENERATIVE MODEL
# (Using StyleGAN as example - adapt for your model)
import dnnlib.tflib as tflib
tflib.init_tf()
# ... load your model here ...

# 2. COLLECT PREFERENCES FROM DATABASE
conn = sqlite3.connect("preferences.db")
c = conn.cursor()
c.execute("SELECT latent_vector_id, rating FROM user_preferences")
preferences = c.fetchall()

# Load latent vectors and ratings
X = []  # Latent vectors
y = []  # Ratings
for latent_id, rating in preferences:
    latent = np.load(f"latents/{latent_id}.npy")
    X.append(latent)
    y.append(rating)

X = np.array(X)
y = np.array(y)

# 3. TRAIN PREFERENCE CLASSIFIER (SVM for speed)
from sklearn.svm import SVC

# Split and scale data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train fast SVM classifier
classifier = SVC(kernel='rbf', C=10, gamma=0.0001)
classifier.fit(X_train_scaled, y_train)
print(f"Accuracy: {classifier.score(X_test_scaled, y_test):.2f}")

# 4. GENERATE PERSONALIZED CONTENT
def find_optimal_latent(classifier, scaler, n_iterations=1000):
    """Find latent vector that maximizes preference score"""
    best_latent = None
    best_score = -1
    
    for _ in range(n_iterations):
        # Random initialization
        latent = np.random.randn(512)
        
        # Simple hill climbing
        for step in range(100):
            # Add small random perturbations
            perturbation = np.random.randn(512) * 0.01
            new_latent = latent + perturbation
            
            # Check if this improves the score
            score = classifier.decision_function(
                scaler.transform(new_latent.reshape(1, -1))
            )[0]
            
            if score > best_score:
                best_score = score
                best_latent = new_latent
                latent = new_latent
    
    return best_latent

# Find and generate optimal content
optimal_latent = find_optimal_latent(classifier, scaler)
# optimal_image = generator.generate(optimal_latent)

print("Found optimal latent vector with preference score:", 
      classifier.predict_proba(
          scaler.transform(optimal_latent.reshape(1, -1))
      )[0][1])</code></pre>
                
                <div class="warning-box">
                    <h4>Important Implementation Details</h4>
                    <ul>
                        <li><strong>Balance your dataset:</strong> Include negative examples to prevent blind spots</li>
                        <li><strong>Use caching:</strong> Pre-generate common samples for instant responses</li>
                        <li><strong>Batch processing:</strong> Generate 100+ samples at once for GPU efficiency</li>
                        <li><strong>Simple feedback:</strong> Binary ratings work better than complex scales</li>
                    </ul>
                </div>
            </section>

            <section id="advanced">
                <h2>Advanced Usage</h2>

                <h3>Multi-Modal Preferences</h3>
                <div class="concept-box">
                    <p>PLGL can work across multiple modalities simultaneously:</p>
                    <ul>
                        <li><strong>Visual + Text:</strong> Learn preferences for images with captions</li>
                        <li><strong>Audio + Visual:</strong> Match music preferences with visual styles</li>
                        <li><strong>Cross-modal transfer:</strong> Apply preferences from one domain to another</li>
                    </ul>
                    <p>The key is to have a shared latent space or a way to map between different latent spaces.</p>
                </div>

                <h3>Conditional Generation</h3>
                <div class="concept-box">
                    <p>Generate content based on both preferences and conditions:</p>
                    <ul>
                        <li><strong>Context-aware:</strong> Different preferences for different moods, times, or situations</li>
                        <li><strong>Multi-user:</strong> Switch between different user preference models</li>
                        <li><strong>Hybrid approach:</strong> Combine prompts with preference learning</li>
                    </ul>
                    <p>This allows for more nuanced personalization that adapts to changing contexts.</p>
                </div>

                <h3>Real-Time Adaptation</h3>
                <div class="concept-box">
                    <p>PLGL can adapt in real-time using efficient classifiers like SVMs:</p>
                    <ul>
                        <li><strong>Fast updates:</strong> SVM-style classifiers can be retrained quickly</li>
                        <li><strong>Online learning:</strong> Update preferences with each interaction</li>
                        <li><strong>Implicit feedback:</strong> Learn from engagement time, skips, or other signals</li>
                        <li><strong>Cached content:</strong> Use pre-generated samples for instant response</li>
                    </ul>
                    <p>The lightweight nature of the preference classifier enables true real-time personalization.</p>
                </div>

                <h3>Distributed Learning</h3>
                <div class="concept-box">
                    <p>PLGL can be implemented in privacy-preserving ways:</p>
                    <ul>
                        <li><strong>Local training:</strong> Each user's preference model stays on their device</li>
                        <li><strong>Federated learning:</strong> Share model updates, not personal data</li>
                        <li><strong>Differential privacy:</strong> Add noise to protect individual preferences</li>
                        <li><strong>Zero-knowledge:</strong> Match preferences without revealing them</li>
                    </ul>
                    <p>This enables personalization at scale while respecting user privacy.</p>
                </div>
            </section>

            <section id="examples">
                <h2>Example Projects</h2>

                <div class="example-grid">
                    <div class="example-card">
                        <h4>üéµ Music Preference Learning</h4>
                        <p>Generate personalized music using MusicVAE</p>
                        <a href="https://github.com/skindeepai/examples/music-generation" class="example-link">View Code ‚Üí</a>
                    </div>

                    <div class="example-card">
                        <h4>üèóÔ∏è Architecture Design</h4>
                        <p>Create buildings matching style preferences</p>
                        <a href="https://github.com/skindeepai/examples/architecture-gan" class="example-link">View Code ‚Üí</a>
                    </div>

                    <div class="example-card">
                        <h4>üß¨ Molecule Discovery</h4>
                        <p>Design molecules with desired properties</p>
                        <a href="https://github.com/skindeepai/examples/molecular-vae" class="example-link">View Code ‚Üí</a>
                    </div>

                    <div class="example-card">
                        <h4>üìö Story Generation</h4>
                        <p>Create narratives matching reading preferences</p>
                        <a href="https://github.com/skindeepai/examples/story-gpt" class="example-link">View Code ‚Üí</a>
                    </div>

                    <div class="example-card">
                        <h4>üëó Fashion Design</h4>
                        <p>Generate clothing matching personal style</p>
                        <a href="https://github.com/skindeepai/examples/fashion-gan" class="example-link">View Code ‚Üí</a>
                    </div>

                    <div class="example-card">
                        <h4>üéÆ Game Level Generation</h4>
                        <p>Create levels matching player preferences</p>
                        <a href="https://github.com/skindeepai/examples/level-vae" class="example-link">View Code ‚Üí</a>
                    </div>
                </div>
            </section>

            <section id="troubleshooting">
                <h2>Troubleshooting</h2>

                <h3>Common Issues</h3>

                <div class="troubleshooting-item">
                    <h4>Preference model not converging</h4>
                    <p><strong>Solution:</strong> Try these approaches:</p>
                    <ul>
                        <li><strong>Collect more diverse preferences:</strong> Use maximum diversity sampling to cover the latent space better</li>
                        <li><strong>Use a simpler model:</strong> Start with a linear SVM classifier before trying deep networks</li>
                        <li><strong>Adjust learning rate:</strong> Try smaller learning rates (0.0001 or lower)</li>
                        <li><strong>Check data quality:</strong> Look for contradictory ratings or insufficient variety</li>
                        <li><strong>Balance your dataset:</strong> Include pre-marked negative examples (e.g., inappropriate content)</li>
                    </ul>
                </div>

                <div class="troubleshooting-item">
                    <h4>Generated content lacks diversity</h4>
                    <p><strong>Solution:</strong> Increase exploration:</p>
                    <ul>
                        <li><strong>Temperature sampling:</strong> Add noise to latent vectors for more variety</li>
                        <li><strong>Multiple starting points:</strong> Optimize from different random initializations</li>
                        <li><strong>Batch generation:</strong> Use 70% exploitation (refining known good areas) and 30% exploration</li>
                        <li><strong>Minimum distance constraints:</strong> Ensure generated samples aren't too similar</li>
                    </ul>
                </div>

                <div class="troubleshooting-item">
                    <h4>Memory or performance issues</h4>
                    <p><strong>Solution:</strong> Use efficient techniques:</p>
                    <ul>
                        <li><strong>GPU batching:</strong> Generate content in batches for efficient GPU utilization</li>
                        <li><strong>Cached content:</strong> Reuse pre-generated samples, especially for initial training</li>
                        <li><strong>SVM classifiers:</strong> Use fast, lightweight classifiers that can handle large datasets</li>
                        <li><strong>Mixed caching strategy:</strong> Combine fresh generations with cached positive/negative examples</li>
                        <li><strong>Gradient checkpointing:</strong> Trade computation for memory when using large models</li>
                    </ul>
                </div>
            </section>

            <div class="next-steps">
                <h2>Next Steps</h2>
                <div class="next-steps-grid">
                    <a href="documentation.html" class="next-step-card">
                        <h3>üìñ Read the Docs</h3>
                        <p>Comprehensive API reference and guides</p>
                    </a>
                    <a href="https://github.com/skindeepai" class="next-step-card">
                        <h3>üíª Explore Code</h3>
                        <p>Dive into the source code on GitHub</p>
                    </a>
                    <a href="https://discord.gg/plgl" class="next-step-card">
                        <h3>üí¨ Join Community</h3>
                        <p>Get help and share your projects</p>
                    </a>
                </div>
            </div>
        </main>
    </div>

    <style>
        .docs-container {
            display: grid;
            grid-template-columns: 250px 1fr;
            min-height: 100vh;
            padding-top: 60px;
        }

        .docs-sidebar {
            background: #F8FAFC;
            padding: 2rem;
            position: sticky;
            top: 60px;
            height: calc(100vh - 60px);
            overflow-y: auto;
        }

        .docs-sidebar h3 {
            margin-bottom: 1rem;
        }

        .docs-sidebar ul {
            list-style: none;
        }

        .docs-sidebar li {
            margin-bottom: 0.5rem;
        }

        .docs-sidebar a {
            color: var(--text-secondary);
            text-decoration: none;
            transition: color 0.3s;
        }

        .docs-sidebar a:hover,
        .docs-sidebar a.active {
            color: var(--primary-color);
        }

        .docs-content {
            padding: 2rem 4rem;
            max-width: 900px;
        }

        .docs-content h1 {
            margin-bottom: 1rem;
        }

        .lead {
            font-size: 1.25rem;
            color: var(--text-secondary);
            margin-bottom: 3rem;
        }

        .docs-content section {
            margin-bottom: 3rem;
        }

        .docs-content h2 {
            margin: 2rem 0 1rem;
            padding-top: 2rem;
        }

        .docs-content h3 {
            margin: 1.5rem 0 0.75rem;
        }

        .docs-content h4 {
            margin: 2rem 0 1rem;
            color: #374151;
            font-weight: 600;
        }

        .docs-content h5 {
            margin: 1.5rem 0 0.75rem;
            color: #4B5563;
            font-weight: 600;
            font-size: 1.1rem;
        }

        .info-box {
            background: #F0F9FF;
            border-left: 4px solid var(--primary-color);
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 0.5rem;
        }

        .info-box h4 {
            margin-bottom: 0.5rem;
        }

        .concept-box {
            background: #F9FAFB;
            border: 1px solid #E5E7EB;
            padding: 1.5rem;
            margin: 1rem 0 2rem;
            border-radius: 0.5rem;
        }

        .concept-box p {
            margin-bottom: 0.75rem;
        }

        .concept-box ul,
        .concept-box ol {
            margin-left: 1.5rem;
            margin-bottom: 0.75rem;
        }

        .concept-box li {
            margin-bottom: 0.5rem;
        }

        .concept-note {
            background: #FEF3C7;
            border-left: 4px solid #F59E0B;
            padding: 1rem;
            margin: 1.5rem 0;
            border-radius: 0.5rem;
            font-style: italic;
        }

        .concept-flow {
            background: #F3F4F6;
            padding: 2rem;
            margin: 1.5rem 0;
            border-radius: 0.5rem;
        }

        .concept-flow h3 {
            margin-bottom: 1rem;
        }

        .concept-flow ol {
            margin-left: 1.5rem;
        }

        .concept-flow li {
            margin-bottom: 1rem;
        }

        .concept-flow li h4 {
            margin-top: 0;
            margin-bottom: 0.5rem;
        }

        .warning-box {
            background: #FEF2F2;
            border-left: 4px solid #EF4444;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 0.5rem;
        }

        .warning-box h4 {
            color: #DC2626;
            margin-bottom: 0.5rem;
        }

        .implementation-note {
            background: #F0F9FF;
            border: 1px solid #3B82F6;
            padding: 1rem;
            margin: 1.5rem 0;
            border-radius: 0.5rem;
        }

        .implementation-note p {
            margin-bottom: 0.5rem;
        }

        .implementation-note p:last-child {
            margin-bottom: 0;
        }

        .example-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 1.5rem;
            margin-top: 1.5rem;
        }

        .example-card {
            background: white;
            border: 1px solid #E5E7EB;
            padding: 1.5rem;
            border-radius: 0.5rem;
            transition: all 0.3s;
        }

        .example-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        .example-link {
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 600;
        }

        .troubleshooting-item {
            background: #FEF3C7;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 0.5rem;
        }

        .next-steps {
            margin-top: 4rem;
            padding-top: 2rem;
            border-top: 1px solid #E5E7EB;
        }

        .next-steps-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 1.5rem;
            margin-top: 1.5rem;
        }

        .next-step-card {
            background: var(--primary-color);
            color: white;
            padding: 2rem;
            border-radius: 0.5rem;
            text-decoration: none;
            transition: all 0.3s;
        }

        .next-step-card:hover {
            transform: translateY(-2px);
            background: var(--secondary-color);
        }

        .next-step-card h3 {
            margin-bottom: 0.5rem;
        }

        @media (max-width: 768px) {
            .docs-container {
                grid-template-columns: 1fr;
            }
            
            .docs-sidebar {
                display: none;
            }
            
            .docs-content {
                padding: 1rem;
            }
            
            .next-steps-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>

    <script src="scripts/main.js"></script>
</body>
</html>